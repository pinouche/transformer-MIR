Implementation of self-attention using a transformer module to tackle multiple instance regression. We use a transformer to 
learn from an undordered sequence (i.e. a set of instance), where there is no temporal/order dependency in the input.
